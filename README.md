# ğŸ§¥ğŸ‘œAutoencoders - Fashion MNISTğŸ¥¾ğŸ‘–

## ğŸ¯ Project Objective
This project explores image compression and reconstruction capabilities using deep learning techniques. By working with the Fashion MNIST dataset, we investigate the process of learning and reproducing fundamental image features through an autoencoder architecture.

## ğŸ§  Methodology

### ğŸ“Š Dataset Analysis
- **Source**: Fashion MNIST
- **Total Samples**: 60,000 training, 10,000 testing
- **Image Characteristics**: 28x28 pixel grayscale
- **Classes**: 10 different fashion product categories

### ğŸ—ï¸ Model Architecture
Our project consists of two primary components:

#### 1. ğŸ” Encoder
- Input Layer: 784 neurons (flattened 28x28 image)
- Layer 1: 256 neurons (ReLU activation)
- Layer 2: 128 neurons (ReLU activation)
- Encoding Layer: 64 neurons (ReLU activation)

#### 2. ğŸ”“ Decoder
- Symmetric inverse of the encoder
- Reconstructing original image from encoded representation
- Final layer: Sigmoid activation for pixel value normalization

### ğŸ“ Performance Evaluation Metrics

#### 1. ğŸ“ˆ Structural Similarity Index (SSIM)
SSIM measures the structural similarity between reconstructed and original images.

**Statistical Results**:
- Average SSIM: 0.7122
- Median SSIM: 0.7308
- SSIM Standard Deviation: 0.1399
- Minimum SSIM: 0.1257
- Maximum SSIM: 0.9779

#### 2. ğŸ“‰ Reconstruction Error
Measures the mean squared error between original and reconstructed images.

**Statistical Results**:
- Mean Error: 0.0133
- Median Error: 0.0110
- Standard Deviation: 0.0088
- Minimum Error: 0.0015
- Maximum Error: 0.0935
## ğŸ” Project Outputs and Observations

### ğŸ“Š Visualizations
Our project includes the following visualizations:
- Original vs Reconstructed Images Comparison
- SSIM Score Distribution
- Reconstruction Error Analysis
- Best and Worst Reconstruction Investigations

### ğŸ’¡ Key Insights
1. The autoencoder successfully captures the fundamental features of images.
2. A 64-dimensional encoding space preserves sufficient information to maintain the essence of images.
3. High SSIM scores indicate that reconstructed images are very similar to original images.

## ğŸš€ Future Research Directions
- Investigate the impact of different encoding dimensions on performance
- Experiment with more complex architectures (CNN-based autoencoders)
- Test similar approaches on different datasets

## ğŸ¨ Potential Use Cases
- Image compression
- Image noise reduction
- Feature extraction
- Dimensionality reduction

## ğŸ› ï¸ Requirements
- ğŸ Python 3.7+
- ğŸ§  TensorFlow
- ğŸ”¢ Keras
- ğŸ“Š NumPy
- ğŸ¼ Pandas
- ğŸ“ˆ Matplotlib
- ğŸŒˆ Seaborn
- ğŸ–¼ï¸ Scikit-image

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ” Code And Kaggle Link
Project: [autoencoders-fashion-mnist.ipynb](https://github.com/omerfarukyuce/Autoencoders-Fashion-mnist/blob/main/autoencoders-fashion-mnist.ipynb)

Kaggle: [ğŸ§¥ğŸ‘œAutoencoders - Fashion MNISTğŸ¥¾ğŸ‘–](https://www.kaggle.com/code/merfarukyce/autoencoders-fashion-mnist)
